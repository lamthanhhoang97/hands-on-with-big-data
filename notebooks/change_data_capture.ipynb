{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00b637ad",
   "metadata": {},
   "source": [
    "# Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b29d8c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from delta import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d775ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/home/ad/Desktop/code/big-data-tools/venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ad/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ad/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-4f658f08-7cee-4a1c-b47f-db2bddf078cd;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.3.0 in central\n",
      "\tfound io.delta#delta-storage;3.3.0 in central\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in central\n",
      ":: resolution report :: resolve 48ms :: artifacts dl 2ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.3.0 from central in [default]\n",
      "\tio.delta#delta-storage;3.3.0 from central in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-4f658f08-7cee-4a1c-b47f-db2bddf078cd\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/3ms)\n",
      "25/05/17 16:47:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = (\n",
    "    pyspark\n",
    "    .sql.SparkSession.builder\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\")\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\")\n",
    "    # Logging\n",
    "    # .config(\"spark.log.level\", \"DEBUG\")\n",
    ")\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "sc = spark.sparkContext # spark context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf69f4",
   "metadata": {},
   "source": [
    "# Create test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7e701b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----------+---------+-----------+----------+-----------------+\n",
      "|userId|    name|       city|operation|sequenceNum|     ts_ms|record_track_hash|\n",
      "+------+--------+-----------+---------+-----------+----------+-----------------+\n",
      "|   124|    Raul|     Oaxaca|   INSERT|          1|2025-02-01|       -357915523|\n",
      "|   123|  Isabel|  Monterrey|   INSERT|          1|2025-02-01|       -883305503|\n",
      "|   125|Mercedes|    Tijuana|   INSERT|          2|2025-03-01|       1432383275|\n",
      "|   126|    Lily|     Cancun|   INSERT|          2|2025-03-01|       1891951372|\n",
      "|   123|    NULL|       NULL|   DELETE|          6|2025-07-01|         85273170|\n",
      "|   125|Mercedes|Guadalajara|   UPDATE|          6|2025-07-01|      -1185033760|\n",
      "|   125|Mercedes|   Mexicali|   UPDATE|          5|2025-06-01|       1041365571|\n",
      "|   123|  Isabel|  Chihuahua|   UPDATE|          5|2025-06-01|       -269450623|\n",
      "+------+--------+-----------+---------+-----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = spark.createDataFrame([\n",
    "    (124, \"Raul\",     \"Oaxaca\",      \"INSERT\", 1),\n",
    "    (123, \"Isabel\",   \"Monterrey\",   \"INSERT\", 1),\n",
    "    (125, \"Mercedes\", \"Tijuana\",     \"INSERT\", 2),\n",
    "    (126, \"Lily\",     \"Cancun\",      \"INSERT\", 2),\n",
    "    (123, None,       None,          \"DELETE\", 6),\n",
    "    (125, \"Mercedes\", \"Guadalajara\", \"UPDATE\", 6),\n",
    "    (125, \"Mercedes\", \"Mexicali\",    \"UPDATE\", 5),\n",
    "    (123, \"Isabel\",   \"Chihuahua\",   \"UPDATE\", 5),\n",
    "    # (125, None,       None,          \"DELETE\", 7), # test\n",
    "], schema=\"userId int, name string, city string, operation string, sequenceNum int\")\n",
    "\n",
    "# add columns\n",
    "test_df = (\n",
    "    test_df\n",
    "    .withColumn(\"ts_ms\", add_months(to_date(lit(\"2025-01-01\")), col(\"sequenceNum\")))\n",
    "    .withColumn(\"record_track_hash\", hash(\"userId\", \"name\", \"city\"))\n",
    ")\n",
    "\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b959d793",
   "metadata": {},
   "source": [
    "# Create Delta Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba05c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/17 16:47:38 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----+-----------+------------------+-----------------+---------------+-----------------+\n",
      "|userId|name|city|sequenceNum|record_active_flag|record_start_date|record_end_date|record_track_hash|\n",
      "+------+----+----+-----------+------------------+-----------------+---------------+-----------------+\n",
      "+------+----+----+-----------+------------------+-----------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_path = '/home/ad/Desktop/code/big-data-tools/notebooks/spark-warehouse/cdc_data'\n",
    "cdc_data = (\n",
    "    DeltaTable\n",
    "    .createOrReplace(spark)\n",
    "    # .createIfNotExists(spark)\n",
    "    # .tableName(\"default.cdc_data\")\n",
    "    .addColumn(\"userId\", dataType=IntegerType())\n",
    "    .addColumn(\"name\", dataType=CharType(30))\n",
    "    .addColumn(\"city\", dataType=CharType(30))\n",
    "    .addColumn(\"sequenceNum\", dataType=IntegerType())\n",
    "    .addColumn(\"record_active_flag\", dataType=BooleanType())\n",
    "    .addColumn(\"record_start_date\", dataType=DateType())\n",
    "    .addColumn(\"record_end_date\", dataType=DateType())\n",
    "    .addColumn(\"record_track_hash\", dataType=IntegerType())\n",
    "    .location(table_path)\n",
    "    # enable CDF\n",
    "    .property('delta.enableChangeDataFeed', 'true')\n",
    "    .execute()\n",
    ")\n",
    "\n",
    "# clean data\n",
    "spark.sql(f\"DELETE FROM delta.`{table_path}` WHERE userId > 0;\")\n",
    "\n",
    "cdc_data.toDF().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d36a31",
   "metadata": {},
   "source": [
    "# Apply changes from CDC to Delta Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69204d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "def apply_changes(\n",
    "    dt,\n",
    "    event_df,\n",
    "    retryable_event_df=None, # out-of-order events from previous batches\n",
    "    record_keys=['userId'],\n",
    "    sequence_by=['sequenceNum']\n",
    "):\n",
    "    # TODO: union incoming events and out-of-order events\n",
    "\n",
    "    # get inserted rows (operation = INSERT)\n",
    "    # run insert command\n",
    "    (\n",
    "        dt.alias(\"target\")\n",
    "        .merge(\n",
    "            event_df.alias(\"source\"), \"target.userId = source.userId\"\n",
    "        )\n",
    "        .whenNotMatchedInsert(\n",
    "            condition=\"operation = 'INSERT'\",\n",
    "            values={\n",
    "                \"target.userId\": \"source.userId\",\n",
    "                \"target.name\": \"source.name\",\n",
    "                \"target.city\": \"source.city\",\n",
    "                \"target.sequenceNum\": \"source.sequenceNum\",\n",
    "                \"target.record_active_flag\": lit(True),\n",
    "                \"target.record_start_date\": \"source.ts_ms\",\n",
    "                \"target.record_end_date\": lit(\"9999-01-01\"),\n",
    "                \"target.record_track_hash\": \"source.record_track_hash\"\n",
    "            }\n",
    "        )\n",
    "        .execute()\n",
    "    )\n",
    "\n",
    "    # get updated rows (operation = UPDATE)\n",
    "    update_df = (\n",
    "        event_df\n",
    "        .filter(\"operation = 'UPDATE'\")\n",
    "        .sort(asc(\"sequenceNum\"))\n",
    "    )\n",
    "\n",
    "    # join with table to get matched ids\n",
    "    matched_df = (\n",
    "        update_df.alias(\"m\")\n",
    "        .join(dt.toDF(), how='left_anti', on=['userId', 'record_track_hash'])\n",
    "        # .select(\"userId\", \"ts_ms\", \"m.record_track_hash\")\n",
    "        .dropDuplicates([\"userId\"])\n",
    "    )\n",
    "    if not matched_df.isEmpty():\n",
    "        # update tracking columns for old records (active_flag, end_date)\n",
    "        (\n",
    "            dt.alias(\"target\")\n",
    "            .merge(\n",
    "                matched_df.alias(\"source\"), \"target.userId = source.userId\"\n",
    "            )\n",
    "            .whenMatchedUpdate(\n",
    "                condition=\"target.record_active_flag = true AND target.record_track_hash != source.record_track_hash\",\n",
    "                set={\n",
    "                    \"target.record_active_flag\": lit(False),\n",
    "                    # \"target.record_end_date\": \"source.ts_ms\"\n",
    "                }\n",
    "            )\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "    if not update_df.isEmpty():\n",
    "        # apply window function to set tracking columns for new records (active_flag, end_date)\n",
    "        window = (\n",
    "            Window\n",
    "            .partitionBy(\"userId\")\n",
    "            .orderBy(desc(\"sequenceNum\"))\n",
    "        )\n",
    "\n",
    "\n",
    "        update_df = (\n",
    "            update_df.alias(\"s\")\n",
    "            .join(\n",
    "                dt.toDF().alias(\"t\"), \n",
    "                on=(col(\"s.userId\") == col(\"t.userId\")) & (col(\"s.record_track_hash\") == col(\"t.record_track_hash\")),\n",
    "                how='left_anti'\n",
    "            )\n",
    "            .withColumn(\"row_num\", row_number().over(window))\n",
    "            .withColumn(\"record_active_flag\", col(\"row_num\") == 1)\n",
    "            .withColumn(\"record_end_date\", when(col(\"record_active_flag\") == lit(True), lit(\"9999-01-01\")).when(col(\"record_active_flag\") == lit(False), col(\"ts_ms\")))\n",
    "            .withColumn(\"mergeKey\", lit(None))\n",
    "        )\n",
    "\n",
    "        # insert updated rows as new records\n",
    "        (\n",
    "            dt.alias(\"target\")\n",
    "            .merge(\n",
    "                update_df.alias(\"source\"), \n",
    "                \"target.userId = source.mergeKey\"\n",
    "            )\n",
    "            .whenNotMatchedInsert(\n",
    "                values={\n",
    "                    \"target.userId\": \"source.userId\",\n",
    "                    \"target.name\": \"source.name\",\n",
    "                    \"target.city\": \"source.city\",\n",
    "                    \"target.sequenceNum\": \"source.sequenceNum\",\n",
    "                    \"target.record_active_flag\": \"source.record_active_flag\",\n",
    "                    \"target.record_start_date\": \"source.ts_ms\",\n",
    "                    \"target.record_end_date\": \"source.record_end_date\",\n",
    "                    \"target.record_track_hash\": \"source.record_track_hash\"\n",
    "                }\n",
    "            )\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "    # get delelted rows (operation = DELETE)\n",
    "    delete_df = event_df.filter(\"operation = 'DELETE'\").dropDuplicates(['userId'])\n",
    "\n",
    "    if not delete_df.isEmpty():\n",
    "        # run delete command\n",
    "        (\n",
    "            dt.alias(\"target\")\n",
    "            .merge(\n",
    "                delete_df.alias(\"source\"), \"target.userId = source.userId\"\n",
    "            )\n",
    "            # soft delete (active_flag = false)\n",
    "            .whenMatchedUpdate(\n",
    "                set={\n",
    "                    'target.record_active_flag': lit(False),\n",
    "                    'target.record_end_date': 'source.ts_ms'\n",
    "                }\n",
    "            )\n",
    "            # .whenMatchedDelete()\n",
    "            .execute()\n",
    "        )\n",
    "\n",
    "    # check out-of-order events\n",
    "    # 1. DELETE/UPDATE before INSERT -> left_anti join\n",
    "    # 2. DELETE before UPDATE (INSERT already exists)\n",
    "    ooo_event_df = event_df.filter(\"operation = 'UPDATE' OR operation = 'DELETE'\")\n",
    "    ooo_event_df = (\n",
    "        ooo_event_df\n",
    "        .join(\n",
    "            dt.toDF(), on=record_keys, how='left_anti'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # write out of order events to streaming error event table for retry later\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e1b6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_changes(cdc_data, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7e8fc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+\n",
      "|userId|name                          |city                          |sequenceNum|record_active_flag|record_start_date|record_end_date|record_track_hash|\n",
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+\n",
      "|124   |Raul                          |Oaxaca                        |1          |true              |2025-02-01       |9999-01-01     |-357915523       |\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |\n",
      "|126   |Lily                          |Cancun                        |2          |true              |2025-03-01       |9999-01-01     |1891951372       |\n",
      "|125   |Mercedes                      |Tijuana                       |2          |false             |2025-03-01       |9999-01-01     |1432383275       |\n",
      "|125   |Mercedes                      |Mexicali                      |5          |false             |2025-06-01       |2025-06-01     |1041365571       |\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |\n",
      "|125   |Mercedes                      |Guadalajara                   |6          |true              |2025-07-01       |9999-01-01     |-1185033760      |\n",
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdc_data.toDF().sort(\"sequenceNum\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "607d7fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------------+------+--------+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|version|timestamp              |userId|userName|operation              |operationParameters                                                                                                                                                                                                        |job |notebook|clusterId|readVersion|isolationLevel|isBlindAppend|operationMetrics                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |userMetadata|engineInfo                         |\n",
      "+-------+-----------------------+------+--------+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "|6      |2025-05-17 16:52:39.031|NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = userId#0)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [], notMatchedBySourcePredicates -> []}                                                                 |NULL|NULL    |NULL     |5          |Serializable  |false        |{numTargetRowsCopied -> 3, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2878, numTargetBytesRemoved -> 2878, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 2, executionTimeMs -> 410, materializeSourceTimeMs -> 127, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 136, numTargetRowsUpdated -> 2, numOutputRows -> 5, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 1, numSourceRows -> 1, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 144} |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|5      |2025-05-17 16:50:03.329|NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = userId#0)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [], notMatchedBySourcePredicates -> []}                                                                 |NULL|NULL    |NULL     |4          |Serializable  |false        |{numTargetRowsCopied -> 3, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2878, numTargetBytesRemoved -> 2881, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 2, executionTimeMs -> 482, materializeSourceTimeMs -> 162, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 162, numTargetRowsUpdated -> 2, numOutputRows -> 5, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 1, numSourceRows -> 1, numTargetFilesRemoved -> 1, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 154} |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|4      |2025-05-17 16:47:44.47 |NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = userId#0)\"], matchedPredicates -> [{\"actionType\":\"update\"}], notMatchedPredicates -> [], notMatchedBySourcePredicates -> []}                                                                 |NULL|NULL    |NULL     |3          |Serializable  |false        |{numTargetRowsCopied -> 3, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2881, numTargetBytesRemoved -> 5179, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 2, executionTimeMs -> 667, materializeSourceTimeMs -> 148, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 332, numTargetRowsUpdated -> 2, numOutputRows -> 5, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 1, numSourceRows -> 1, numTargetFilesRemoved -> 2, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 185} |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|3      |2025-05-17 16:47:43.487|NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = cast(mergeKey#4134 as int))\"], matchedPredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}                                               |NULL|NULL    |NULL     |2          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2464, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 778, materializeSourceTimeMs -> 1, numTargetRowsInserted -> 3, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 0, numTargetRowsUpdated -> 0, numOutputRows -> 3, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 3, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 776}        |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|2      |2025-05-17 16:47:42.348|NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = userId#0)\"], matchedPredicates -> [{\"predicate\":\"NOT (record_track_hash#192 = record_track_hash#17)\",\"actionType\":\"update\"}], notMatchedPredicates -> [], notMatchedBySourcePredicates -> []}|NULL|NULL    |NULL     |1          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 1, numTargetBytesAdded -> 2715, numTargetBytesRemoved -> 4520, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 2, executionTimeMs -> 1245, materializeSourceTimeMs -> 588, numTargetRowsInserted -> 0, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 382, numTargetRowsUpdated -> 2, numOutputRows -> 2, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 1, numSourceRows -> 2, numTargetFilesRemoved -> 2, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 271}|NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|1      |2025-05-17 16:47:40.678|NULL  |NULL    |MERGE                  |{predicate -> [\"(userId#185 = userId#0)\"], matchedPredicates -> [], notMatchedPredicates -> [{\"actionType\":\"insert\"}], notMatchedBySourcePredicates -> []}                                                                 |NULL|NULL    |NULL     |0          |Serializable  |false        |{numTargetRowsCopied -> 0, numTargetRowsDeleted -> 0, numTargetFilesAdded -> 4, numTargetBytesAdded -> 8969, numTargetBytesRemoved -> 0, numTargetDeletionVectorsAdded -> 0, numTargetRowsMatchedUpdated -> 0, executionTimeMs -> 778, materializeSourceTimeMs -> 1, numTargetRowsInserted -> 4, numTargetRowsMatchedDeleted -> 0, numTargetDeletionVectorsUpdated -> 0, scanTimeMs -> 0, numTargetRowsUpdated -> 0, numOutputRows -> 4, numTargetDeletionVectorsRemoved -> 0, numTargetRowsNotMatchedBySourceUpdated -> 0, numTargetChangeFilesAdded -> 0, numSourceRows -> 4, numTargetFilesRemoved -> 0, numTargetRowsNotMatchedBySourceDeleted -> 0, rewriteTimeMs -> 774}        |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "|0      |2025-05-17 16:47:37.428|NULL  |NULL    |CREATE OR REPLACE TABLE|{partitionBy -> [], clusterBy -> [], description -> NULL, isManaged -> false, properties -> {\"delta.enableChangeDataFeed\":\"true\"}}                                                                                         |NULL|NULL    |NULL     |NULL       |Serializable  |true         |{}                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |NULL        |Apache-Spark/3.5.4 Delta-Lake/3.3.0|\n",
      "+-------+-----------------------+------+--------+-----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----+--------+---------+-----------+--------------+-------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+------------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdc_data.history().show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1de304b",
   "metadata": {},
   "source": [
    "# Change data feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7ed83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+----------------+---------------+-----------------------+\n",
      "|userId|name                          |city                          |sequenceNum|record_active_flag|record_start_date|record_end_date|record_track_hash|_change_type    |_commit_version|_commit_timestamp      |\n",
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+----------------+---------------+-----------------------+\n",
      "|126   |Lily                          |Cancun                        |2          |true              |2025-03-01       |9999-01-01     |1891951372       |insert          |1              |2025-05-17 16:47:40.678|\n",
      "|123   |Isabel                        |Monterrey                     |1          |true              |2025-02-01       |9999-01-01     |-883305503       |insert          |1              |2025-05-17 16:47:40.678|\n",
      "|124   |Raul                          |Oaxaca                        |1          |true              |2025-02-01       |9999-01-01     |-357915523       |insert          |1              |2025-05-17 16:47:40.678|\n",
      "|125   |Mercedes                      |Tijuana                       |2          |true              |2025-03-01       |9999-01-01     |1432383275       |insert          |1              |2025-05-17 16:47:40.678|\n",
      "|123   |Isabel                        |Monterrey                     |1          |true              |2025-02-01       |9999-01-01     |-883305503       |update_preimage |2              |2025-05-17 16:47:42.348|\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |9999-01-01     |-883305503       |update_postimage|2              |2025-05-17 16:47:42.348|\n",
      "|125   |Mercedes                      |Tijuana                       |2          |true              |2025-03-01       |9999-01-01     |1432383275       |update_preimage |2              |2025-05-17 16:47:42.348|\n",
      "|125   |Mercedes                      |Tijuana                       |2          |false             |2025-03-01       |9999-01-01     |1432383275       |update_postimage|2              |2025-05-17 16:47:42.348|\n",
      "|123   |Isabel                        |Chihuahua                     |5          |true              |2025-06-01       |9999-01-01     |-269450623       |insert          |3              |2025-05-17 16:47:43.487|\n",
      "|125   |Mercedes                      |Guadalajara                   |6          |true              |2025-07-01       |9999-01-01     |-1185033760      |insert          |3              |2025-05-17 16:47:43.487|\n",
      "|125   |Mercedes                      |Mexicali                      |5          |false             |2025-06-01       |2025-06-01     |1041365571       |insert          |3              |2025-05-17 16:47:43.487|\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |9999-01-01     |-883305503       |update_preimage |4              |2025-05-17 16:47:44.47 |\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |update_postimage|4              |2025-05-17 16:47:44.47 |\n",
      "|123   |Isabel                        |Chihuahua                     |5          |true              |2025-06-01       |9999-01-01     |-269450623       |update_preimage |4              |2025-05-17 16:47:44.47 |\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |update_postimage|4              |2025-05-17 16:47:44.47 |\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |update_preimage |5              |2025-05-17 16:50:03.329|\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |update_postimage|5              |2025-05-17 16:50:03.329|\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |update_preimage |5              |2025-05-17 16:50:03.329|\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |update_postimage|5              |2025-05-17 16:50:03.329|\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |update_preimage |6              |2025-05-17 16:52:39.031|\n",
      "|123   |Isabel                        |Monterrey                     |1          |false             |2025-02-01       |2025-07-01     |-883305503       |update_postimage|6              |2025-05-17 16:52:39.031|\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |update_preimage |6              |2025-05-17 16:52:39.031|\n",
      "|123   |Isabel                        |Chihuahua                     |5          |false             |2025-06-01       |2025-07-01     |-269450623       |update_postimage|6              |2025-05-17 16:52:39.031|\n",
      "+------+------------------------------+------------------------------+-----------+------------------+-----------------+---------------+-----------------+----------------+---------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# read changes from batch queries\n",
    "change_df = (\n",
    "  spark.read\n",
    "  .format(\"delta\")\n",
    "  .option(\"readChangeFeed\", \"true\")\n",
    "  .option(\"startingVersion\", 0) # or startingTimestamp\n",
    "  .load(table_path)\n",
    ")\n",
    "\n",
    "change_df.sort(\"_commit_version\", \"_commit_timestamp\").show(truncate=False, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa08b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
